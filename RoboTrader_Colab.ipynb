{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusFelippeMeira/AppEmpreiteiros/blob/main/RoboTrader_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
        "from tpot import TPOTClassifier\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox, ttk\n",
        "import openai\n",
        "import os\n",
        "import signal\n",
        "import platform\n",
        "import json\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import parallel_backend\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Configuração para evitar problemas de subprocessos\n",
        "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"\n",
        "\n",
        "# Verifica o sistema operacional\n",
        "SISTEMA = platform.system()\n",
        "\n",
        "# Configuração inicial\n",
        "# Ajuste para caminho relativo ou adaptativo por sistema operacional\n",
        "if SISTEMA == \"Windows\":\n",
        "    output_dir = r\"C:\\\\Users\\\\Matheus\\\\Desktop\\\\Matheus Trabalho Digital\\\\PoketeOption\\\\Modelo IA APRENDIZAGEM\"\n",
        "else:\n",
        "    # No Linux, usamos o diretório home do usuário\n",
        "    output_dir = os.path.join(os.path.expanduser(\"~\"), \"RoboTrader/modelo_ia\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "model_path = os.path.join(output_dir, \"melhor_modelo.pt\")\n",
        "\n",
        "# Configuração da API OpenAI\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai.api_key:\n",
        "    raise ValueError(\"Chave da API OpenAI não configurada. Defina a variável OPENAI_API_KEY no ambiente.\")\n",
        "\n",
        "# Definição do modelo PyTorch\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Configuração do modelo\n",
        "input_size = 6  # Número de características\n",
        "hidden_size = 64\n",
        "output_size = 3  # Classes: Compre, Venda, Aguarde\n",
        "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "# Verificar se o modelo salvo existe ou criar novo\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(f\"Modelo carregado de: {model_path}\")\n",
        "else:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Novo modelo criado e salvo em: {model_path}\")\n",
        "\n",
        "# Função para tocar som compatível com diferentes sistemas operacionais\n",
        "def tocar_som(recomendacao):\n",
        "    try:\n",
        "        if SISTEMA == \"Windows\":\n",
        "            import winsound\n",
        "            if recomendacao == \"Compre\":\n",
        "                winsound.Beep(1000, 500)  # Som para 'Compre'\n",
        "            elif recomendacao == \"Venda\":\n",
        "                winsound.Beep(500, 500)  # Som para 'Venda'\n",
        "            elif recomendacao == \"Aguarde\":\n",
        "                winsound.Beep(750, 300)  # Som neutro para 'Aguarde'\n",
        "        elif SISTEMA == \"Linux\":\n",
        "            # Uso de comandos de terminal para som no Linux\n",
        "            freq = \"1000\" if recomendacao == \"Compre\" else \"500\" if recomendacao == \"Venda\" else \"750\"\n",
        "            duration = \"0.5\" if recomendacao == \"Compre\" else \"0.5\" if recomendacao == \"Venda\" else \"0.3\"\n",
        "            os.system(f\"play -n synth {duration} sine {freq} 2>/dev/null || echo 'Som não suportado'\")\n",
        "        elif SISTEMA == \"Darwin\":  # macOS\n",
        "            os.system(f\"afplay /System/Library/Sounds/Tink.aiff\")\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível reproduzir som: {e}\")\n",
        "\n",
        "# Classe PocketOption\n",
        "class PocketOption:\n",
        "    def __init__(self, ssid):\n",
        "        self.ssid = ssid\n",
        "        self.connected = False\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            print(f\"Conectando com a Pocket Option usando SSID: {self.ssid}\")\n",
        "            # Simulação de conexão - em ambiente real, implementar a conexão real\n",
        "            self.connected = True\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao conectar: {e}\")\n",
        "            self.connected = False\n",
        "            return False\n",
        "\n",
        "    def get_candles(self, ativo):\n",
        "        if not self.connected:\n",
        "            print(\"Não conectado. Reconectando...\")\n",
        "            self.connect()\n",
        "\n",
        "        print(f\"Obtendo candles para o ativo {ativo}...\")\n",
        "        candles = []\n",
        "        for i in range(20):\n",
        "            open_price = round(random.uniform(1.100, 1.150), 3)\n",
        "            close_price = round(random.uniform(1.100, 1.150), 3)\n",
        "            high_price = round(max(open_price, close_price) + random.uniform(0.001, 0.01), 3)\n",
        "            low_price = round(min(open_price, close_price) - random.uniform(0.001, 0.01), 3)\n",
        "            low_price = max(low_price, 0)  # Garantir que low não seja menor que zero\n",
        "\n",
        "            candles.append({\n",
        "                \"timestamp\": time.time() - (i * 60),\n",
        "                \"open\": open_price,\n",
        "                \"close\": close_price,\n",
        "                \"high\": high_price,\n",
        "                \"low\": low_price,\n",
        "                \"volume\": random.randint(1000, 5000),\n",
        "            })\n",
        "        return candles\n",
        "\n",
        "# Funções auxiliares de validação e análise\n",
        "def validar_dados_candles(candles):\n",
        "    for idx, candle in enumerate(candles):\n",
        "        if candle[\"open\"] < 0 or candle[\"close\"] < 0 or candle[\"high\"] < 0 or candle[\"low\"] < 0:\n",
        "            raise ValueError(f\"Candle inválido (valores negativos) no índice {idx}: {candle}\")\n",
        "        if candle[\"high\"] < candle[\"low\"]:\n",
        "            raise ValueError(f\"Erro lógico no candle {idx}: high < low. Dados: {candle}\")\n",
        "    return True\n",
        "\n",
        "def detectar_padroes(candles):\n",
        "    validar_dados_candles(candles)\n",
        "\n",
        "    if detectar_three_white_soldiers(candles):\n",
        "        return \"three_white_soldiers\"\n",
        "    if detectar_three_black_crows(candles):\n",
        "        return \"three_black_crows\"\n",
        "    if detectar_morning_star(candles):\n",
        "        return \"morning_star\"\n",
        "    if detectar_evening_star(candles):\n",
        "        return \"evening_star\"\n",
        "    if detectar_piercing_line(candles):\n",
        "        return \"piercing_line\"\n",
        "\n",
        "    return None\n",
        "\n",
        "def detectar_three_white_soldiers(candles):\n",
        "    if len(candles) < 3:\n",
        "        return False\n",
        "    c1, c2, c3 = candles[-3:]\n",
        "    return (\n",
        "        c1[\"close\"] > c1[\"open\"] and c2[\"close\"] > c2[\"open\"] and c3[\"close\"] > c3[\"open\"]\n",
        "        and c1[\"close\"] < c2[\"open\"] and c2[\"close\"] < c3[\"open\"]\n",
        "        and abs(c1[\"close\"] - c1[\"open\"]) > (c1[\"high\"] - c1[\"low\"]) * 0.5\n",
        "        and abs(c2[\"close\"] - c2[\"open\"]) > (c2[\"high\"] - c2[\"low\"]) * 0.5\n",
        "        and abs(c3[\"close\"] - c3[\"open\"]) > (c3[\"high\"] - c3[\"low\"]) * 0.5\n",
        "    )\n",
        "\n",
        "def detectar_three_black_crows(candles):\n",
        "    if len(candles) < 3:\n",
        "        return False\n",
        "    c1, c2, c3 = candles[-3:]\n",
        "    return (\n",
        "        c1[\"close\"] < c1[\"open\"] and c2[\"close\"] < c2[\"open\"] and c3[\"close\"] < c3[\"open\"]\n",
        "        and c1[\"close\"] > c2[\"open\"] and c2[\"close\"] > c3[\"open\"]\n",
        "        and abs(c1[\"close\"] - c1[\"open\"]) > (c1[\"high\"] - c1[\"low\"]) * 0.5\n",
        "        and abs(c2[\"close\"] - c2[\"open\"]) > (c2[\"high\"] - c2[\"low\"]) * 0.5\n",
        "        and abs(c3[\"close\"] - c3[\"open\"]) > (c3[\"high\"] - c3[\"low\"]) * 0.5\n",
        "    )\n",
        "\n",
        "def detectar_morning_star(candles):\n",
        "    if len(candles) < 3:\n",
        "        return False\n",
        "    c1, c2, c3 = candles[-3:]\n",
        "    return (\n",
        "        c1[\"close\"] < c1[\"open\"]\n",
        "        and abs(c2[\"close\"] - c2[\"open\"]) < (c2[\"high\"] - c2[\"low\"]) * 0.2\n",
        "        and c3[\"close\"] > c3[\"open\"] and c3[\"close\"] > c1[\"open\"]\n",
        "    )\n",
        "\n",
        "def detectar_evening_star(candles):\n",
        "    if len(candles) < 3:\n",
        "        return False\n",
        "    c1, c2, c3 = candles[-3:]\n",
        "    return (\n",
        "        c1[\"close\"] > c1[\"open\"]\n",
        "        and abs(c2[\"close\"] - c2[\"open\"]) < (c2[\"high\"] - c2[\"low\"]) * 0.2\n",
        "        and c3[\"close\"] < c3[\"open\"] and c3[\"close\"] < c1[\"open\"]\n",
        "    )\n",
        "\n",
        "def detectar_piercing_line(candles):\n",
        "    if len(candles) < 2:\n",
        "        return False\n",
        "    c1, c2 = candles[-2:]\n",
        "    return (\n",
        "        c1[\"close\"] < c1[\"open\"]\n",
        "        and c2[\"open\"] < c1[\"close\"]\n",
        "        and c2[\"close\"] > (c1[\"open\"] + c1[\"close\"]) / 2\n",
        "    )\n",
        "\n",
        "def calcular_topos_fundos(candles):\n",
        "    highs = [c[\"high\"] for c in candles]\n",
        "    lows = [c[\"low\"] for c in candles]\n",
        "    return max(highs), min(lows)\n",
        "\n",
        "def calcular_momentum(candles):\n",
        "    tamanhos = [abs(c[\"close\"] - c[\"open\"]) for c in candles]\n",
        "    return {\n",
        "        \"current_candle_size\": tamanhos[-1],\n",
        "        \"average_candle_size\": np.mean(tamanhos),\n",
        "    }\n",
        "\n",
        "def calcular_volatilidade(candles):\n",
        "    highs = np.array([c[\"high\"] for c in candles])\n",
        "    lows = np.array([c[\"low\"] for c in candles])\n",
        "    closes = np.array([c[\"close\"] for c in candles])\n",
        "\n",
        "    previous_closes = np.roll(closes, 1)\n",
        "    previous_closes[0] = closes[0]\n",
        "\n",
        "    tr = np.maximum(highs - lows, np.maximum(abs(highs - previous_closes), abs(lows - previous_closes)))\n",
        "    atr = np.mean(tr)\n",
        "    desvio_padrao = np.std(closes)\n",
        "\n",
        "    return {\n",
        "        \"atr\": atr,\n",
        "        \"std_dev\": desvio_padrao\n",
        "    }\n",
        "\n",
        "def analisar_contexto(candles):\n",
        "    closes = [c[\"close\"] for c in candles]\n",
        "    sma_short = np.mean(closes[-10:])\n",
        "    sma_long = np.mean(closes[-20:])\n",
        "    tendencia = \"alta\" if sma_short > sma_long else \"baixa\"\n",
        "\n",
        "    atr = calcular_volatilidade(candles)[\"atr\"]\n",
        "    lateralizado = atr < 0.01\n",
        "\n",
        "    return {\"tendencia\": tendencia, \"lateralizado\": lateralizado}\n",
        "\n",
        "def detectar_rompimento(candles):\n",
        "    closes = [c[\"close\"] for c in candles]\n",
        "    highs = [c[\"high\"] for c in candles]\n",
        "    lows = [c[\"low\"] for c in candles]\n",
        "\n",
        "    suporte = min(lows[-5:])\n",
        "    resistencia = max(highs[-5:])\n",
        "    preco_atual = closes[-1]\n",
        "\n",
        "    rompimento_suporte = preco_atual < suporte\n",
        "    rompimento_resistencia = preco_atual > resistencia\n",
        "\n",
        "    return {\"rompeu_suporte\": rompimento_suporte, \"rompeu_resistencia\": rompimento_resistencia}\n",
        "\n",
        "def gerar_dados(candles):\n",
        "    topos_fundos = calcular_topos_fundos(candles)\n",
        "    padrao = detectar_padroes(candles)\n",
        "    momentum = calcular_momentum(candles)\n",
        "    volatilidade = calcular_volatilidade(candles)\n",
        "\n",
        "    return {\n",
        "        \"candles\": candles,\n",
        "        \"topos_fundos\": topos_fundos,\n",
        "        \"patterns\": padrao,\n",
        "        \"momentum\": momentum,\n",
        "        \"volatility\": volatilidade,\n",
        "    }\n",
        "\n",
        "def usar_rede_neural_pytorch(dados):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        caracteristicas = torch.tensor([\n",
        "            [\n",
        "                dados[\"topos_fundos\"][0],\n",
        "                dados[\"topos_fundos\"][1],\n",
        "                dados[\"momentum\"][\"current_candle_size\"],\n",
        "                dados[\"momentum\"][\"average_candle_size\"],\n",
        "                dados[\"volatility\"][\"atr\"],\n",
        "                dados[\"volatility\"][\"std_dev\"]\n",
        "            ]\n",
        "        ], dtype=torch.float32)\n",
        "\n",
        "        predicao = model(caracteristicas)\n",
        "        classe_predita = torch.argmax(predicao, dim=1).item()\n",
        "\n",
        "        if classe_predita == 0:\n",
        "            return \"Compre\"\n",
        "        elif classe_predita == 1:\n",
        "            return \"Venda\"\n",
        "        else:\n",
        "            return \"Aguarde\"\n",
        "\n",
        "def consultar_chatgpt(dados):\n",
        "    mensagem = (\n",
        "        f\"Analise os seguintes dados de price action e forneça uma recomendação de compra, venda ou espera:\\n\"\n",
        "        f\"- Topo máximo e fundo mínimo: {dados['topos_fundos']}\\n\"\n",
        "        f\"- Padrão detectado: {dados['patterns']}\\n\"\n",
        "        f\"- Momentum: {dados['momentum']}\\n\"\n",
        "        f\"- Volatilidade (ATR e desvio padrão): {dados['volatility']}\\n\"\n",
        "        f\"- Contexto de mercado: {analisar_contexto(dados['candles'])}\\n\"\n",
        "        f\"- Rompimento de suporte ou resistência: {detectar_rompimento(dados['candles'])}\\n\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        resposta = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Você é um especialista em análise técnica de price action.\"},\n",
        "                {\"role\": \"user\", \"content\": mensagem}\n",
        "            ]\n",
        "        )\n",
        "        conteudo = resposta[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
        "\n",
        "        if \"compre\" in conteudo:\n",
        "            return \"Compre\"\n",
        "        elif \"venda\" in conteudo:\n",
        "            return \"Venda\"\n",
        "        else:\n",
        "            return \"Aguarde\"\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao consultar OpenAI: {e}\")\n",
        "        return usar_rede_neural_pytorch(dados)\n",
        "\n",
        "def pre_analise(dados):\n",
        "    contexto = analisar_contexto(dados[\"candles\"])\n",
        "    rompimento = detectar_rompimento(dados[\"candles\"])\n",
        "    topo, fundo = dados[\"topos_fundos\"]\n",
        "    padrao_detectado = dados[\"patterns\"] is not None\n",
        "    momentum_significativo = dados[\"momentum\"][\"current_candle_size\"] > 1.35 * dados[\"momentum\"][\"average_candle_size\"]\n",
        "    volatilidade_adequada = dados[\"volatility\"][\"atr\"] > 0.015\n",
        "\n",
        "    pontuacao = 0\n",
        "    if padrao_detectado:\n",
        "        pontuacao += 1.2\n",
        "    if momentum_significativo:\n",
        "        pontuacao += 1\n",
        "    if volatilidade_adequada:\n",
        "        pontuacao += 0.7\n",
        "    if contexto[\"tendencia\"] == \"alta\" and not contexto[\"lateralizado\"]:\n",
        "        pontuacao += 1\n",
        "    if rompimento[\"rompeu_resistencia\"]:\n",
        "        pontuacao += 1\n",
        "    elif rompimento[\"rompeu_suporte\"]:\n",
        "        pontuacao -= 1\n",
        "\n",
        "    print(f\"Pontuação final da pré-análise: {pontuacao}\")\n",
        "    return pontuacao >= 2.5\n",
        "\n",
        "# Nova classe para IA supervisora\n",
        "class SupervisorIA:\n",
        "    def __init__(self, log_path=None):\n",
        "        \"\"\"\n",
        "        Inicializa a IA supervisora que monitora o sistema principal\n",
        "\n",
        "        :param log_path: Caminho para salvar os logs. Se None, usa o diretório padrão\n",
        "        \"\"\"\n",
        "        if log_path is None:\n",
        "            if SISTEMA == \"Windows\":\n",
        "                self.log_path = os.path.join(output_dir, \"supervisor_logs\")\n",
        "            else:\n",
        "                self.log_path = os.path.join(os.path.expanduser(\"~\"), \"RoboTrader/supervisor_logs\")\n",
        "        else:\n",
        "            self.log_path = log_path\n",
        "\n",
        "        os.makedirs(self.log_path, exist_ok=True)\n",
        "\n",
        "        # Modelo de detecção de anomalias\n",
        "        self.anomaly_detector = IsolationForest(contamination=0.05, random_state=42)\n",
        "\n",
        "        # Histórico de recomendações para análise\n",
        "        self.historico_recomendacoes = []\n",
        "\n",
        "        # Métricas de confiabilidade\n",
        "        self.metricas = {\n",
        "            \"total_analises\": 0,\n",
        "            \"inconsistencias\": 0,\n",
        "            \"anomalias_detectadas\": 0,\n",
        "            \"ultima_verificacao\": None\n",
        "        }\n",
        "\n",
        "        # Histórico de desempenho do sistema principal\n",
        "        self.historico_desempenho = []\n",
        "\n",
        "        # Verificar se há arquivo de histórico e carregar\n",
        "        self.arquivo_historico = os.path.join(self.log_path, \"historico_supervisor.json\")\n",
        "        self.carregar_historico()\n",
        "\n",
        "        print(f\"Supervisor IA iniciado. Logs salvos em: {self.log_path}\")\n",
        "\n",
        "    def carregar_historico(self):\n",
        "        \"\"\"Carrega o histórico de dados de um arquivo JSON se existir\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self.arquivo_historico):\n",
        "                with open(self.arquivo_historico, 'r') as f:\n",
        "                    dados = json.load(f)\n",
        "                    self.historico_recomendacoes = dados.get('historico_recomendacoes', [])\n",
        "                    self.metricas = dados.get('metricas', self.metricas)\n",
        "                    self.historico_desempenho = dados.get('historico_desempenho', [])\n",
        "                print(f\"Histórico carregado: {len(self.historico_recomendacoes)} registros\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar histórico: {e}\")\n",
        "\n",
        "    def salvar_historico(self):\n",
        "        \"\"\"Salva o histórico de dados em um arquivo JSON\"\"\"\n",
        "        try:\n",
        "            dados = {\n",
        "                'historico_recomendacoes': self.historico_recomendacoes,\n",
        "                'metricas': self.metricas,\n",
        "                'historico_desempenho': self.historico_desempenho\n",
        "            }\n",
        "            with open(self.arquivo_historico, 'w') as f:\n",
        "                json.dump(dados, f)\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao salvar histórico: {e}\")\n",
        "\n",
        "    def analisar_decisao(self, dados, recomendacao_principal, recomendacao_secundaria=None):\n",
        "        \"\"\"\n",
        "        Analisa a decisão tomada pelo sistema principal\n",
        "\n",
        "        :param dados: Dados usados para a análise\n",
        "        :param recomendacao_principal: Recomendação do sistema principal (ChatGPT)\n",
        "        :param recomendacao_secundaria: Recomendação secundária (Rede Neural)\n",
        "        :return: Tupla (aprovado, confianca, feedback)\n",
        "        \"\"\"\n",
        "        # Registrar a recomendação no histórico\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        registro = {\n",
        "            'timestamp': timestamp,\n",
        "            'dados': {\n",
        "                'topos_fundos': dados['topos_fundos'],\n",
        "                'patterns': dados['patterns'],\n",
        "                'momentum_atual': dados['momentum']['current_candle_size'],\n",
        "                'momentum_medio': dados['momentum']['average_candle_size'],\n",
        "                'atr': dados['volatility']['atr'],\n",
        "                'std_dev': dados['volatility']['std_dev']\n",
        "            },\n",
        "            'recomendacao_principal': recomendacao_principal\n",
        "        }\n",
        "\n",
        "        if recomendacao_secundaria:\n",
        "            registro['recomendacao_secundaria'] = recomendacao_secundaria\n",
        "\n",
        "        self.historico_recomendacoes.append(registro)\n",
        "        self.metricas['total_analises'] += 1\n",
        "\n",
        "        # Verificar inconsistências entre recomendações\n",
        "        inconsistencia = False\n",
        "        if recomendacao_secundaria and recomendacao_principal != recomendacao_secundaria:\n",
        "            inconsistencia = True\n",
        "            self.metricas['inconsistencias'] += 1\n",
        "\n",
        "        # Analisar anomalias nos dados\n",
        "        anomalia = self.verificar_anomalias(dados)\n",
        "        if anomalia:\n",
        "            self.metricas['anomalias_detectadas'] += 1\n",
        "\n",
        "        # Calcular confiança na recomendação\n",
        "        confianca = self.calcular_confianca(dados, inconsistencia, anomalia)\n",
        "\n",
        "        # Gerar feedback\n",
        "        feedback = self.gerar_feedback(dados, recomendacao_principal,\n",
        "                                       recomendacao_secundaria, confianca)\n",
        "\n",
        "        # Atualizar métricas\n",
        "        self.metricas['ultima_verificacao'] = timestamp\n",
        "\n",
        "        # Salvar histórico periodicamente\n",
        "        if len(self.historico_recomendacoes) % 10 == 0:\n",
        "            self.salvar_historico()\n",
        "\n",
        "        # Decisão final\n",
        "        aprovado = confianca >= 0.7\n",
        "\n",
        "        return aprovado, confianca, feedback\n",
        "\n",
        "    def verificar_anomalias(self, dados):\n",
        "        \"\"\"Verifica se há anomalias nos dados de entrada\"\"\"\n",
        "        # Se temos poucos dados, treinar o modelo primeiro\n",
        "        if len(self.historico_recomendacoes) >= 10:\n",
        "            # Extrair características de dados históricos para treinar\n",
        "            X_historico = []\n",
        "            for reg in self.historico_recomendacoes[-50:]:  # Usamos os últimos 50 registros\n",
        "                X_historico.append([\n",
        "                    reg['dados']['topos_fundos'][0],\n",
        "                    reg['dados']['topos_fundos'][1],\n",
        "                    reg['dados']['momentum_atual'],\n",
        "                    reg['dados']['momentum_medio'],\n",
        "                    reg['dados']['atr'],\n",
        "                    reg['dados']['std_dev']\n",
        "                ])\n",
        "\n",
        "            # Treinar o detector de anomalias\n",
        "            if len(X_historico) > 5:  # Precisamos de pelo menos alguns exemplos\n",
        "                self.anomaly_detector.fit(X_historico)\n",
        "\n",
        "                # Verificar o dado atual\n",
        "                X_atual = [[\n",
        "                    dados['topos_fundos'][0],\n",
        "                    dados['topos_fundos'][1],\n",
        "                    dados['momentum']['current_candle_size'],\n",
        "                    dados['momentum']['average_candle_size'],\n",
        "                    dados['volatility']['atr'],\n",
        "                    dados['volatility']['std_dev']\n",
        "                ]]\n",
        "\n",
        "                # -1 para anomalias, 1 para dados normais\n",
        "                resultado = self.anomaly_detector.predict(X_atual)\n",
        "                return resultado[0] == -1\n",
        "\n",
        "        return False\n",
        "\n",
        "    def calcular_confianca(self, dados, inconsistencia, anomalia):\n",
        "        \"\"\"Calcula um valor de confiança para a recomendação\"\"\"\n",
        "        # Base de confiança\n",
        "        confianca = 0.8\n",
        "\n",
        "        # Reduzir confiança se houver inconsistência nas recomendações\n",
        "        if inconsistencia:\n",
        "            confianca -= 0.3\n",
        "\n",
        "        # Reduzir confiança se houver anomalias nos dados\n",
        "        if anomalia:\n",
        "            confianca -= 0.4\n",
        "\n",
        "        # Ajustar confiança com base nas características dos dados\n",
        "        # Padrões de candlestick conhecidos aumentam a confiança\n",
        "        if dados['patterns'] is not None:\n",
        "            confianca += 0.1\n",
        "\n",
        "        # Momentum significativo\n",
        "        if dados['momentum']['current_candle_size'] > 1.5 * dados['momentum']['average_candle_size']:\n",
        "            confianca += 0.05\n",
        "\n",
        "        # Alta volatilidade reduz levemente a confiança (mais incerteza)\n",
        "        if dados['volatility']['atr'] > 0.02:\n",
        "            confianca -= 0.05\n",
        "\n",
        "        # Garantir que a confiança esteja entre 0 e 1\n",
        "        return max(0.0, min(1.0, confianca))\n",
        "\n",
        "    def gerar_feedback(self, dados, recomendacao_principal, recomendacao_secundaria, confianca):\n",
        "        \"\"\"Gera feedback explicativo sobre a análise\"\"\"\n",
        "        feedback = []\n",
        "\n",
        "        # Analisar contexto de mercado\n",
        "        contexto = analisar_contexto(dados['candles'])\n",
        "        tendencia = contexto['tendencia']\n",
        "        lateralizado = contexto['lateralizado']\n",
        "\n",
        "        # Verificar se a recomendação está alinhada com a tendência\n",
        "        alinhado_tendencia = (\n",
        "            (tendencia == \"alta\" and recomendacao_principal == \"Compre\") or\n",
        "            (tendencia == \"baixa\" and recomendacao_principal == \"Venda\")\n",
        "        )\n",
        "\n",
        "        # Comentários sobre confiança\n",
        "        if confianca > 0.9:\n",
        "            feedback.append(\"Alta confiança na recomendação.\")\n",
        "        elif confianca < 0.6:\n",
        "            feedback.append(\"Baixa confiança, considere aguardar.\")\n",
        "\n",
        "        # Comentários sobre inconsistências\n",
        "        if recomendacao_secundaria and recomendacao_principal != recomendacao_secundaria:\n",
        "            feedback.append(f\"Inconsistência entre análises: IA principal sugere {recomendacao_principal}, rede neural sugere {recomendacao_secundaria}.\")\n",
        "\n",
        "        # Comentários sobre tendência\n",
        "        if not alinhado_tendencia and recomendacao_principal != \"Aguarde\":\n",
        "            feedback.append(f\"Recomendação contrária à tendência de {tendencia}.\")\n",
        "\n",
        "        # Comentários sobre padrões\n",
        "        if dados['patterns']:\n",
        "            feedback.append(f\"Padrão {dados['patterns']} detectado, aumentando confiabilidade.\")\n",
        "\n",
        "        # Comentários sobre volatilidade\n",
        "        if dados['volatility']['atr'] > 0.025:\n",
        "            feedback.append(\"Alta volatilidade detectada, considere reduzir exposição.\")\n",
        "\n",
        "        # Comentários sobre movimento lateral\n",
        "        if lateralizado and recomendacao_principal != \"Aguarde\":\n",
        "            feedback.append(\"Mercado lateralizado, recomendação pode ser prematura.\")\n",
        "\n",
        "        return \" \".join(feedback)\n",
        "\n",
        "    def obter_estatisticas(self):\n",
        "        \"\"\"Retorna estatísticas sobre o desempenho do supervisor\"\"\"\n",
        "        taxa_inconsistencia = 0\n",
        "        if self.metricas['total_analises'] > 0:\n",
        "            taxa_inconsistencia = self.metricas['inconsistencias'] / self.metricas['total_analises']\n",
        "\n",
        "        return {\n",
        "            \"total_analises\": self.metricas['total_analises'],\n",
        "            \"taxa_inconsistencia\": f\"{taxa_inconsistencia:.2%}\",\n",
        "            \"anomalias_detectadas\": self.metricas['anomalias_detectadas'],\n",
        "            \"ultima_verificacao\": self.metricas['ultima_verificacao']\n",
        "        }\n",
        "\n",
        "def atualizar_recomendacao_thread(ativo):\n",
        "    try:\n",
        "        candles = pocket_option.get_candles(ativo)\n",
        "        dados = gerar_dados(candles)\n",
        "\n",
        "        if pre_analise(dados):\n",
        "            recomendacao_principal = consultar_chatgpt(dados)\n",
        "            # Obter segunda opinião da rede neural\n",
        "            recomendacao_secundaria = usar_rede_neural_pytorch(dados)\n",
        "\n",
        "            # Supervisão da IA\n",
        "            aprovado, confianca, feedback = supervisor.analisar_decisao(\n",
        "                dados, recomendacao_principal, recomendacao_secundaria)\n",
        "\n",
        "            # Formatação da confiança\n",
        "            confianca_str = f\"{confianca:.0%}\"\n",
        "\n",
        "            # Decidir se aceita a recomendação com base na aprovação do supervisor\n",
        "            if not aprovado:\n",
        "                recomendacao = \"Aguarde\"\n",
        "                texto_recomendacao = f\"Recomendação: {recomendacao} (confiança insuficiente: {confianca_str})\"\n",
        "            else:\n",
        "                recomendacao = recomendacao_principal\n",
        "                texto_recomendacao = f\"Recomendação: {recomendacao} (confiança: {confianca_str})\"\n",
        "\n",
        "            labels_recomendacoes[ativo].config(text=texto_recomendacao)\n",
        "\n",
        "            # Atualizar o texto de feedback\n",
        "            if ativo in labels_feedback:\n",
        "                labels_feedback[ativo].config(text=f\"Análise: {feedback}\")\n",
        "        else:\n",
        "            recomendacao = \"Aguarde\"\n",
        "            labels_recomendacoes[ativo].config(text=f\"Recomendação: {recomendacao}\")\n",
        "            if ativo in labels_feedback:\n",
        "                labels_feedback[ativo].config(text=\"Análise: Pré-análise indica espera.\")\n",
        "\n",
        "        tocar_som(recomendacao)\n",
        "\n",
        "        # Atualiza o status para \"Aguardando\" após 30 segundos\n",
        "        root.after(30000, lambda: labels_recomendacoes[ativo].config(text=\"Recomendação: Aguardando...\"))\n",
        "    except Exception as e:\n",
        "        labels_recomendacoes[ativo].config(text=f\"Erro: {str(e)[:30]}...\")\n",
        "        label_status.config(text=\"Status: Erro de conexão\", fg=\"red\")\n",
        "        # Tentar reconectar em caso de falha\n",
        "        try:\n",
        "            pocket_option.connect()\n",
        "            if pocket_option.connected:\n",
        "                label_status.config(text=\"Status: Reconectado\", fg=\"green\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "def criar_interface():\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Análise de Mercado - RoboTrader com IA Supervisora\")\n",
        "\n",
        "    # Configuração de estilo\n",
        "    style = ttk.Style()\n",
        "    if SISTEMA != \"Windows\":  # Tema específico para Linux/Mac\n",
        "        try:\n",
        "            style.theme_use('clam')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Configurar cores e estilos\n",
        "    bg_color = \"#f0f0f0\"\n",
        "    root.configure(bg=bg_color)\n",
        "\n",
        "    # Criar notebook para abas\n",
        "    notebook = ttk.Notebook(root)\n",
        "    notebook.pack(fill='both', expand=True, padx=10, pady=10)\n",
        "\n",
        "    # Aba principal para ativos\n",
        "    tab_ativos = ttk.Frame(notebook)\n",
        "    notebook.add(tab_ativos, text=\"Ativos\")\n",
        "\n",
        "    # Aba para estatísticas e supervisão\n",
        "    tab_supervisor = ttk.Frame(notebook)\n",
        "    notebook.add(tab_supervisor, text=\"Supervisão IA\")\n",
        "\n",
        "    # Controles na aba principal\n",
        "    ativos = [\"Boeing Company OTC\", \"Apple Inc OTC\", \"American Express OTC\"]\n",
        "    global labels_recomendacoes, labels_feedback\n",
        "    labels_recomendacoes = {}\n",
        "    labels_feedback = {}\n",
        "\n",
        "    # Frame para exibir o status da conexão\n",
        "    frame_status = ttk.Frame(tab_ativos)\n",
        "    frame_status.pack(pady=5, fill='x')\n",
        "    global label_status\n",
        "    label_status = ttk.Label(frame_status, text=\"Status: Conectado\", foreground=\"green\")\n",
        "    label_status.pack()\n",
        "\n",
        "    for ativo in ativos:\n",
        "        frame = ttk.LabelFrame(tab_ativos, text=ativo)\n",
        "        frame.pack(pady=10, padx=10, fill='x')\n",
        "\n",
        "        label_recomendacao = ttk.Label(frame, text=\"Recomendação: Aguardando...\", font=(\"Arial\", 12))\n",
        "        label_recomendacao.pack(pady=5)\n",
        "        labels_recomendacoes[ativo] = label_recomendacao\n",
        "\n",
        "        # Adiciona label para feedback do supervisor\n",
        "        label_feedback = ttk.Label(frame, text=\"Análise: Aguardando...\", wraplength=350)\n",
        "        label_feedback.pack(pady=5)\n",
        "        labels_feedback[ativo] = label_feedback\n",
        "\n",
        "    # Botão para forçar atualização\n",
        "    def forcar_atualizacao():\n",
        "        atualizar_todos_ativos()\n",
        "\n",
        "    btn_frame = ttk.Frame(tab_ativos)\n",
        "    btn_frame.pack(pady=10)\n",
        "    btn_atualizar = ttk.Button(btn_frame, text=\"Atualizar Agora\", command=forcar_atualizacao)\n",
        "    btn_atualizar.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "    # Botão para abrir configurações\n",
        "    btn_config = ttk.Button(btn_frame, text=\"Configurações\",\n",
        "                           command=lambda: messagebox.showinfo(\"Configurações\",\n",
        "                                                              \"Funcionalidade de configurações em desenvolvimento.\"))\n",
        "    btn_config.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "    # Conteúdo da aba de supervisão\n",
        "    supervisor_frame = ttk.LabelFrame(tab_supervisor, text=\"Estatísticas da IA Supervisora\")\n",
        "    supervisor_frame.pack(pady=10, padx=10, fill='both', expand=True)\n",
        "\n",
        "    # Labels para estatísticas\n",
        "    labels_estatisticas = {}\n",
        "    for stat in [\"Total de análises\", \"Taxa de inconsistência\", \"Anomalias detectadas\", \"Última verificação\"]:\n",
        "        frame = ttk.Frame(supervisor_frame)\n",
        "        frame.pack(pady=5, fill='x')\n",
        "\n",
        "        ttk.Label(frame, text=f\"{stat}:\", width=20).pack(side=tk.LEFT)\n",
        "        label_valor = ttk.Label(frame, text=\"Carregando...\")\n",
        "        label_valor.pack(side=tk.LEFT)\n",
        "        labels_estatisticas[stat] = label_valor\n",
        "\n",
        "    # Função para atualizar estatísticas\n",
        "    def atualizar_estatisticas():\n",
        "        estat = supervisor.obter_estatisticas()\n",
        "        labels_estatisticas[\"Total de análises\"].config(text=str(estat[\"total_analises\"]))\n",
        "        labels_estatisticas[\"Taxa de inconsistência\"].config(text=estat[\"taxa_inconsistencia\"])\n",
        "        labels_estatisticas[\"Anomalias detectadas\"].config(text=str(estat[\"anomalias_detectadas\"]))\n",
        "        labels_estatisticas[\"Última verificação\"].config(\n",
        "            text=estat[\"ultima_verificacao\"] if estat[\"ultima_verificacao\"] else \"Nunca\")\n",
        "\n",
        "        # Agendar próxima atualização\n",
        "        root.after(5000, atualizar_estatisticas)\n",
        "\n",
        "    # Botões específicos da aba de supervisão\n",
        "    btn_frame_sup = ttk.Frame(tab_supervisor)\n",
        "    btn_frame_sup.pack(pady=10)\n",
        "\n",
        "    ttk.Button(btn_frame_sup, text=\"Atualizar Estatísticas\",\n",
        "              command=atualizar_estatisticas).pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "    ttk.Button(btn_frame_sup, text=\"Exportar Dados\",\n",
        "              command=lambda: messagebox.showinfo(\"Exportar\",\n",
        "                                                \"Os dados serão exportados para \" +\n",
        "                                                supervisor.log_path)).pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "    # Monitora a tecla ESC para sair\n",
        "    root.bind('<Escape>', lambda e: root.destroy())\n",
        "\n",
        "    def iniciar_thread(ativo):\n",
        "        threading.Thread(target=atualizar_recomendacao_thread, args=(ativo,), daemon=True).start()\n",
        "\n",
        "    def atualizar_todos_ativos():\n",
        "        for ativo in ativos:\n",
        "            iniciar_thread(ativo)\n",
        "\n",
        "    def atualizar_periodicamente():\n",
        "        atualizar_todos_ativos()\n",
        "        root.after(60000, atualizar_periodicamente)\n",
        "\n",
        "    # Iniciar atualizações\n",
        "    atualizar_periodicamente()\n",
        "    atualizar_estatisticas()\n",
        "\n",
        "    # Tratamento de encerramento limpo\n",
        "    def encerrar_aplicacao():\n",
        "        print(\"Encerrando aplicação...\")\n",
        "        # Salvar dados do supervisor\n",
        "        if 'supervisor' in globals():\n",
        "            supervisor.salvar_historico()\n",
        "        root.destroy()\n",
        "\n",
        "    # Registra handler para sinais de interrupção\n",
        "    if SISTEMA != \"Windows\":  # No Windows o comportamento é diferente\n",
        "        signal.signal(signal.SIGINT, lambda sig, frame: encerrar_aplicacao())\n",
        "        signal.signal(signal.SIGTERM, lambda sig, frame: encerrar_aplicacao())\n",
        "\n",
        "    # Adiciona exibição da versão\n",
        "    versao_label = ttk.Label(root, text=\"RoboTrader v1.2.0 com IA Supervisora\", font=(\"Arial\", 8))\n",
        "    versao_label.pack(side=tk.BOTTOM, pady=5)\n",
        "\n",
        "    return root\n",
        "\n",
        "def main():\n",
        "    global pocket_option, supervisor\n",
        "    ssid = \"2a231e5c0ad9e70da50416f16e45371\"\n",
        "\n",
        "    try:\n",
        "        print(\"Iniciando RoboTrader com IA Supervisora...\")\n",
        "\n",
        "        # Inicializar a IA supervisora\n",
        "        supervisor = SupervisorIA()\n",
        "\n",
        "        pocket_option = PocketOption(ssid)\n",
        "        if pocket_option.connect():\n",
        "            print(\"Conexão estabelecida com sucesso.\")\n",
        "            root = criar_interface()\n",
        "            root.mainloop()\n",
        "        else:\n",
        "            print(\"Erro ao conectar com a Pocket Option.\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nPrograma encerrado pelo usuário.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro fatal na aplicação: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YEAK3RMA4agH",
        "outputId": "12f9d194-1b2c-408c-9ab8-62891b2dd339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tpot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ada110cafcd4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtpot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tpot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FjFvu4aW4cgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Conheça o Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}